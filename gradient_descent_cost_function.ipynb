{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "#Comparision of value of 'm' and 'b' found by sklearn and by gradient descent algorithm.\r\n",
                "import numpy as np\r\n",
                "import math\r\n",
                "from sklearn import linear_model"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "#Data points and some values.\r\n",
                "x=np.array([1,2,3,4,5])\r\n",
                "y=np.array([5,7,9,11,13])\r\n",
                "n = len(x)\r\n",
                "cost_previous = 0\r\n",
                "m_curr = b_curr = 0\r\n",
                "learning_rate = 0.001"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "#sklearn algorithm(find 'm' and 'b')\r\n",
                "x_mod = np.reshape(x, (-1, 1))\r\n",
                "lm = linear_model.LinearRegression()\r\n",
                "lm.fit(x_mod, y)\r\n",
                "print(\"By sklearn\")\r\n",
                "print(\"m = {}, b = {}\".format(lm.coef_, lm.intercept_))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "By sklearn\n",
                        "m = [2.], b = 3.0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "#Gradient descent algorithm(find 'm' and 'b')\r\n",
                "for i in range(10000):       \r\n",
                "    y_pred = m_curr * x + b_curr\r\n",
                "    cost = (1/n) * sum((y - y_pred)**2)\r\n",
                "    md = -(2/n) * sum(x * (y - y_pred))\r\n",
                "    bd = -(2/n) * sum(y - y_pred)\r\n",
                "    m_curr = m_curr - (learning_rate * md)\r\n",
                "    b_curr = b_curr - (learning_rate * bd)\r\n",
                "    if (math.isclose(cost, cost_previous, rel_tol=1e-20)):#rel-tol is the relative tolerance. How many times the value should be come same.\r\n",
                "        break\r\n",
                "    # print(\"m_curr = {}, b_curr = {}, cost = {}, iteration = {}\"\r\n",
                "    # .format(m_curr, b_curr, cost, i))\r\n",
                "print(\"By gradient descent algorithm\")\r\n",
                "print(\"m = {}, b = {}\".format(round(m_curr), round(b_curr)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "By gradient descent algorithm\n",
                        "m = 2, b = 3\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#check up code\r\n",
                "cost1 = sum((y - x)**2)\r\n",
                "cost2 = sum([val**2 for val in (y - x)])\r\n",
                "cost1, cost2"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.2",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.2 64-bit"
        },
        "interpreter": {
            "hash": "04dab57e78248bc5235021efaca3862c9054ea03675166f084d8c1a7ef1d3271"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}